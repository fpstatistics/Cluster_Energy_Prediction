{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ripser import ripser\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取文件夹下多个数据\n",
    "def load_data(file_dir):\n",
    "    pos = []\n",
    "    energy = []\n",
    "    file_list = os.listdir(file_dir) ##文件列表\n",
    "    for i1 in file_list:\n",
    "        # orig_os = os.getcwd()  ##返回当前的工作目录 \n",
    "        pos_tmp = []\n",
    "        energy_tmp = []\n",
    "        os.chdir(file_dir)    ## ./data/Au20_OPT_1000/ 更改工作目录\n",
    "        with open(i1,'r') as df:\n",
    "            dfread = df.read()\n",
    "            match_tmp1 = re.findall(r\"\\n.*\", dfread)##正则化匹配，.表示匹配除了\\n之外的内容，返回的是一个列表\n",
    "            energy_tmp.append(float(match_tmp1[0]))\n",
    "            match_tmp2 = re.findall(r\"Au.*\", dfread)\n",
    "            # print(match_tmp2)\n",
    "            for pop_i in range(len(match_tmp2)):\n",
    "                xyz = match_tmp2[pop_i].split(\"    \")\n",
    "                x, y, z = float(xyz[1]), float(xyz[2]), float(xyz[3])\n",
    "                pos_tmp.append([x, y, z])\n",
    "        # os.chdir(orig_os)\n",
    "        pos = pos + pos_tmp ##每个文件的数据接在一起\n",
    "        energy = energy + energy_tmp \n",
    "    pos = np.array(pos)\n",
    "    energy = np.array(energy)\n",
    "    return pos, energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_dir_Au = 'D:/Vs_projects/MathorCup/origin_data/Au20_OPT_1000'\n",
    "# file_dir_Au = 'D:/Vs_projects/MathorCup/test_data'\n",
    "pos_tmp_Au, energy_Au = load_data(file_dir_Au)# \n",
    "pos_Au = pos_tmp_Au.reshape(-1, 20, 3)"
   ]
  },
  {
   "source": [
    "## Parameter selection for Sutton-Chen potential energy function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SC_potential_energy_func(x, a): ##需要训练的势能函数\n",
    "    n = 10\n",
    "    m = 8\n",
    "    c = 34.408\n",
    "    # a = 1\n",
    "    epsilon = 1\n",
    "\n",
    "    dis_mat = np.array(dist_matric(x))\n",
    "    tmp1 = (dis_mat / a + np.eye(dis_mat.shape[0])) ** (-n) - np.eye(dis_mat.shape[0])\n",
    "    tmp2 = (dis_mat / a + np.eye(dis_mat.shape[0])) ** (-m) - np.eye(dis_mat.shape[0])\n",
    "    vr = 1 / 2 * (np.sum(tmp1, axis=1))\n",
    "    vd = -c * np.sqrt(np.sum(tmp2, axis=1))\n",
    "    energy = epsilon * np.sum(vr + vd)\n",
    "    return energy\n",
    "\n",
    "def dist_matric(pos):    \n",
    "    dis_mat=[]\n",
    "    for def_i in range(0,len(pos)):\n",
    "        dis_mat.append([])\n",
    "        for def_j in range(0,len(pos)):\n",
    "            temp=math.sqrt(math.pow(pos[def_j][0]-pos[def_i][0],2)+math.pow(pos[def_j][1]-pos[def_i][1],2)+math.pow(pos[def_j][2]-pos[def_i][2],2))\n",
    "            dis_mat[def_i].append(temp)\n",
    "    return(dis_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(label,pred):\n",
    "    return np.mean(np.abs(label - pred))\n",
    "\n",
    "def parameter_selection(data, para_grid):\n",
    "    error_total = []\n",
    "    for para in para_grid:\n",
    "        error_l = 0\n",
    "        for i in range(data.shape[0]):\n",
    "            ene = SC_potential_energy_func(data[i],para)\n",
    "            err = criterion(energy_Au[i],ene)\n",
    "            error_l += err\n",
    "        error_total.append(error_l)\n",
    "    error_total = np.array(error_total)\n",
    "    indx = np.argmin(error_total)\n",
    "    return para_grid[indx], np.min(error_total/data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameter for Au20: 2.698492462311558\nTrain error: 78.99850092276058\n"
     ]
    }
   ],
   "source": [
    "Au_a = np.linspace(1, 3, 200)\n",
    "best_Au_a, error_Au_train = parameter_selection(pos_Au[:800], Au_a)\n",
    "print(\"Best parameter for Au20:\", best_Au_a)\n",
    "print(\"Train error:\", error_Au_train)\n",
    "_, error_Au_test = parameter_selection(pos_Au[800:], [best_Au_a])\n",
    "print(\"Test error:\", error_Au_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SC_energy_func(x, idx):  ##训练好的势能函数\r\n",
    "    n = 10\r\n",
    "    m = 8\r\n",
    "    c = 34.408\r\n",
    "    a = best_Au_a\r\n",
    "    # epsilon = best_Au_epsilon\r\n",
    "    epsilon = 1\r\n",
    "    x = np.array(x)\r\n",
    "    new_Au_pos_ = np.vstack((new_Au_pos[:idx], np.vstack((x, new_Au_pos[idx+1:]))))\r\n",
    "    new_dis = np.array(dist_matric(new_Au_pos_))\r\n",
    "    new_dis_diag = np.diag(new_dis)\r\n",
    "    tmp1 = (new_dis / a + np.eye(new_dis.shape[0])) ** (-n) - np.eye(new_dis.shape[0])\r\n",
    "    tmp2 = (new_dis / a + np.eye(new_dis.shape[0])) ** (-m) - np.eye(new_dis.shape[0])\r\n",
    "    vr = 1 / 2 * (np.sum(tmp1, axis=1))\r\n",
    "    vd = -c * np.sqrt(np.sum(tmp2, axis=1))\r\n",
    "    energy = epsilon * np.sum(vr + vd)\r\n",
    "    return energy"
   ]
  },
  {
   "source": [
    "## Topology Feature Generation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_matric(pos):    \n",
    "    dis_mat=[]\n",
    "    for def_i in range(0,len(pos)):\n",
    "        dis_mat.append([])\n",
    "        for def_j in range(0,len(pos)):\n",
    "            temp=math.sqrt(math.pow(pos[def_j][0]-pos[def_i][0],2)+math.pow(pos[def_j][1]-pos[def_i][1],2)+math.pow(pos[def_j][2]-pos[def_i][2],2))\n",
    "            dis_mat[def_i].append(temp)\n",
    "    return(dis_mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos2betti(pos):\n",
    "    betti=[]\n",
    "    for i1 in range(len(pos)):\n",
    "        dis_m=dist_matric(pos[i1])\n",
    "        ripser_tmp=ripser(np.array(dis_m),maxdim=2,distance_matrix=True)\n",
    "        ripser_tmp2=ripser_tmp.get('dgms')\n",
    "        betti0_tmp=ripser_tmp2[0]\n",
    "        betti1_tmp=ripser_tmp2[1]\n",
    "        betti2_tmp=ripser_tmp2[2]\n",
    "        betti0=[]\n",
    "        betti1=[]\n",
    "        betti2=[]\n",
    "        betti3=[]\n",
    "        betti0_ini=[]\n",
    "        betti1_ini=[]\n",
    "        betti2_ini=[]\n",
    "        betti0_fin=[]\n",
    "        betti1_fin=[]\n",
    "        betti2_fin=[]\n",
    "        i_thresh_mat=list(map(lambda x:x/far_x,range(0,far_x*10+1,1)))\n",
    "        for i_thresh in range(len(i_thresh_mat)-1):\n",
    "            betti0.append(0)\n",
    "            betti1.append(0)\n",
    "            betti2.append(0)\n",
    "            betti3.append(0)\n",
    "            betti0_ini.append(0)\n",
    "            betti1_ini.append(0)\n",
    "            betti2_ini.append(0)\n",
    "            betti0_fin.append(0)\n",
    "            betti1_fin.append(0)\n",
    "            betti2_fin.append(0)\n",
    "            for i2 in range(len(betti0_tmp)):\n",
    "                if i_thresh_mat[i_thresh] >= betti0_tmp[i2][0] and betti0_tmp[i2][1]>=i_thresh_mat[i_thresh+1]:\n",
    "                    betti0[i_thresh]=betti0[i_thresh]+1\n",
    "                elif i_thresh_mat[i_thresh] < betti0_tmp[i2][1] and betti0_tmp[i2][1]<i_thresh_mat[i_thresh+1]:\n",
    "                    betti0[i_thresh]=betti0[i_thresh]+1\n",
    "            for i3 in range(len(betti1_tmp)):\n",
    "                if (i_thresh_mat[i_thresh] >= betti1_tmp[i3][0] and betti1_tmp[i3][1]>=i_thresh_mat[i_thresh+1]):\n",
    "                    betti1[i_thresh]=betti1[i_thresh]+1\n",
    "                elif (i_thresh_mat[i_thresh] < betti1_tmp[i3][0] and betti1_tmp[i3][1]<i_thresh_mat[i_thresh+1]):\n",
    "                    betti1[i_thresh]=betti1[i_thresh]+1\n",
    "                elif (i_thresh_mat[i_thresh] < betti1_tmp[i3][0] and betti1_tmp[i3][0]<i_thresh_mat[i_thresh+1]):\n",
    "                    betti1[i_thresh]=betti1[i_thresh]+1\n",
    "                elif (i_thresh_mat[i_thresh] < betti1_tmp[i3][1] and betti1_tmp[i3][1]<i_thresh_mat[i_thresh+1]):\n",
    "                    betti1[i_thresh]=betti1[i_thresh]+1\n",
    "            for i4 in range(len(betti2_tmp)):\n",
    "                if i_thresh_mat[i_thresh] >= betti2_tmp[i4][0] and betti2_tmp[i4][1]>=i_thresh_mat[i_thresh+1]:\n",
    "                    betti2[i_thresh]=betti2[i_thresh]+1\n",
    "                elif i_thresh_mat[i_thresh] < betti2_tmp[i4][0] and betti2_tmp[i4][1]<i_thresh_mat[i_thresh+1]:\n",
    "                    betti2[i_thresh]=betti2[i_thresh]+1\n",
    "                elif i_thresh_mat[i_thresh] < betti2_tmp[i4][0] and betti2_tmp[i4][0]<i_thresh_mat[i_thresh+1]:\n",
    "                    betti2[i_thresh]=betti2[i_thresh]+1\n",
    "                elif i_thresh_mat[i_thresh] < betti2_tmp[i4][1] and betti2_tmp[i4][1]<i_thresh_mat[i_thresh+1]:\n",
    "                    betti2[i_thresh]=betti2[i_thresh]+1\n",
    "\n",
    "            for i5 in range(len(dis_m)-1):\n",
    "                for i6 in range(i5+1,len(dis_m)):\n",
    "                    if i_thresh_mat[i_thresh] < dis_m[i5][i6] <=i_thresh_mat[i_thresh+1] :\n",
    "                        betti3[i_thresh]=betti3[i_thresh]+1\n",
    "        betti.append(betti0+betti1+betti2+betti3)\n",
    "    return np.array(betti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pos_Au \n",
    "energy = energy_Au\n",
    "far_x=10\n",
    "betti0 = pos2betti(data)\n",
    "print(len(betti0[0]\n",
    "train_data = betti0[:800]\n",
    "test_data = betti0[800:]\n",
    "test_data_SC= data[800:]\n",
    "train_label = energy[:800]\n",
    "test_label = energy[800:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = total_data[:800]\n",
    "#  test_data = total_data8700:]# # train_label = total_label8:700# \n",
    "# test_label = total_lab8l[70\n",
    "train_data = betti0[:800]\n",
    "test_data = betti0[800:]\n",
    "test_data_SC= data[800:]\n",
    "train_label = energy[:800]\n",
    "test_label = energy[800:]0# :]\n",
    "train_data = total_data[:25# 00]\n",
    "test_data = total_data[25# 00:]\n",
    "train_label = total_label[:# 2500]\n",
    "test_label = total_label[2500:]\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Train label shape:\", train_label.shape)\n",
    "print(\"Train label shape:\", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 画出一个结构的barcode图\n",
    "plot_barcode(data[4], \"BarCode.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立模型\n",
    "\n",
    "neigh = KNeighborsRegressor(n_neighbors=20)\n",
    "knn = neigh.fit(train_data, train_label)\n",
    "pred = knn.predict(test_data)\n",
    "error_bar = abs(pred - test_label)\n",
    "gbr = GradientBoostingRegressor(loss = 'ls',\n",
    "                                learning_rate = 0.1,\n",
    "                                n_estimators = 20,\n",
    "                                subsample = 0.6, \n",
    "                                criterion = 'friedman_mse',\n",
    "                                min_samples_split = 50,\n",
    "                                max_depth = 3,\n",
    "                                random_state = 20,\n",
    "                                alpha = 0.9,\n",
    "                                verbose = 0)\n",
    "model = gbr.fit(train_data, train_label)\n",
    "pred_gbr = model.predict(test_data)\n",
    "err_bar_gbr = abs(pred_gbr - test_label)\n",
    "# mse = sklearn.metrics.mean_squared_error(test_label, pred_gbr, sample_weight=None, multioutput='uniform_average')\n",
    "# mae = sklearn.metrics.mean_absolute_error(test_label, pred_gbr, sample_weight=None, multioutput='uniform_average')\n",
    "# print(\"MSE:\", mse)\n",
    "# print(\"MAE:\", mae)\n",
    "error_SC = []\n",
    "test_data_SC = data[800:]\n",
    "a = Au_a \n",
    "for i in range(len(test_label)):\n",
    "    error_SC.append(abs(test_label[i] - SC_potential_energy_func(test_data_SC[i], a)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,9),dpi = 200)\n",
    "plot_result = {\"KNN\":error_bar,\"GBR\":err_bar_gbr}\n",
    "plot_result = pd.DataFrame(plot_result)\n",
    "plot_result.plot.box()\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.savefig(\"ML_Box.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(error_SC)\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.xticks(ticks=[1],labels=[\"Sutton-Chen\"])\n",
    "plt.savefig(\"SC_Box.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\r\n",
    "    def __init__(self,x0, idx):\r\n",
    "        self.idx = idx\r\n",
    "        self.position_i=[]          # particle position\r\n",
    "        self.velocity_i=[]          # particle velocity\r\n",
    "        self.pos_best_i=[]          # best position individual\r\n",
    "        self.err_best_i = -1          # best error individual\r\n",
    "        self.err_i=-1               # error individual\r\n",
    "\r\n",
    "        for i in range(0,num_dimensions):\r\n",
    "            self.velocity_i.append(random.uniform(-1,1))\r\n",
    "            self.position_i.append(x0[i])\r\n",
    "\r\n",
    "    # evaluate current fitness\r\n",
    "    def evaluate(self,costFunc):\r\n",
    "        self.err_i=costFunc(self.position_i, self.idx)\r\n",
    "\r\n",
    "        # check to see if the current position is an individual best\r\n",
    "        if self.err_i < self.err_best_i or self.err_best_i==-1:\r\n",
    "            self.pos_best_i=self.position_i\r\n",
    "            self.err_best_i=self.err_i\r\n",
    "\r\n",
    "    # update new particle velocity\r\n",
    "    def update_velocity(self,pos_best_g):\r\n",
    "        w=0.5       # constant inertia weight (how much to weigh the previous velocity)\r\n",
    "        c1=1        # cognative constant\r\n",
    "        c2=2        # social constant\r\n",
    "\r\n",
    "        for i in range(0,num_dimensions):\r\n",
    "            r1=random.random()\r\n",
    "            r2=random.random()\r\n",
    "\r\n",
    "            vel_cognitive=c1*r1*(self.pos_best_i[i]-self.position_i[i])\r\n",
    "            vel_social=c2*r2*(pos_best_g[i]-self.position_i[i])\r\n",
    "            self.velocity_i[i]=w*self.velocity_i[i]+vel_cognitive+vel_social\r\n",
    "\r\n",
    "    # update the particle position based off new velocity updates\r\n",
    "    def update_position(self,bounds):\r\n",
    "        for i in range(0,num_dimensions):\r\n",
    "            self.position_i[i]=self.position_i[i]+self.velocity_i[i]\r\n",
    "\r\n",
    "            # adjust maximum position if necessary\r\n",
    "            if self.position_i[i]>bounds[i][1]:\r\n",
    "                self.position_i[i]=bounds[i][1]\r\n",
    "\r\n",
    "            # adjust minimum position if neseccary\r\n",
    "            if self.position_i[i] < bounds[i][0]:\r\n",
    "                self.position_i[i]=bounds[i][0]\r\n",
    "                \r\n",
    "class PSO():\r\n",
    "    def __init__(self, costFunc, x0, idx, bounds, num_particles, maxiter):\r\n",
    "        global num_dimensions\r\n",
    "\r\n",
    "        num_dimensions=len(x0)\r\n",
    "        self.err_best_g = -1                   # best error for group                   # best position for group\r\n",
    "        self.maxiter = maxiter\r\n",
    "        self.num_particles = num_particles\r\n",
    "        self.bounds = bounds\r\n",
    "        self.idx = idx\r\n",
    "        self.x0 = x0\r\n",
    "        self.costFunc = costFunc\r\n",
    "\r\n",
    "    \r\n",
    "    def pso(self):\r\n",
    "        pos_best_g=[]\r\n",
    "        # establish the swarm\r\n",
    "        swarm=[]\r\n",
    "        for i in range(0,self.num_particles):\r\n",
    "            swarm.append(Particle(self.x0, self.idx))\r\n",
    "\r\n",
    "        # begin optimization loop\r\n",
    "        i=0\r\n",
    "        while i < self.maxiter:\r\n",
    "            #print i,err_best_g\r\n",
    "            # cycle through particles in swarm and evaluate fitness\r\n",
    "            for j in range(0,self.num_particles):\r\n",
    "                swarm[j].evaluate(self.costFunc)\r\n",
    "\r\n",
    "                # determine if current particle is the best (globally)\r\n",
    "                if swarm[j].err_i < self.err_best_g or self.err_best_g == -1:\r\n",
    "                    pos_best_g=list(swarm[j].position_i)\r\n",
    "                    self.err_best_g=float(swarm[j].err_i)\r\n",
    "\r\n",
    "            # cycle through swarm and update velocities and position\r\n",
    "            for j in range(0,self.num_particles):\r\n",
    "                swarm[j].update_velocity(pos_best_g)\r\n",
    "                swarm[j].update_position(self.bounds)\r\n",
    "            i+=1\r\n",
    "        return pos_best_g, self.err_best_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_Au_init = pos_Au[0]\n",
    "new_Au_pos = pos_Au_init\n",
    "energy_Au_init = SC_energy_func(pos_Au_init[0], 0)\n",
    "print(\"orig pos:\\n\", pos_Au_init)\n",
    "print(\"orig energy:\\n\", energy_Au_init)\n",
    "print(\"real energy:\\n\", energy_Au[0])\n",
    "### set bounds\n",
    "x_max_Au = np.max(pos_Au[:,:,0])\n",
    "x_min_Au = np.min(pos_Au[:,:,0])\n",
    "y_max_Au = np.max(pos_Au[:,:,1])\n",
    "y_min_Au = np.min(pos_Au[:,:,1])\n",
    "z_max_Au = np.max(pos_Au[:,:,2])\n",
    "z_min_Au = np.min(pos_Au[:,:,2])\n",
    "x_Au_bounds = (x_min_Au, x_max_Au)\n",
    "y_Au_bounds = (y_min_Au, y_max_Au)\n",
    "z_Au_bounds = (z_min_Au, z_max_Au)\n",
    "pos_Au_final = []\n",
    "err_Au_final = []\n",
    "\n",
    "Au_bounds = [x_Au_bounds, y_Au_bounds, z_Au_bounds]\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    pos_Au_final_tmp = []\n",
    "    err_Au_final_tmp = []\n",
    "    for i in range(pos_Au_init.shape[0]):\n",
    "        if epoch == 0 and i == 0:\n",
    "            new_Au_pos = pos_Au_init\n",
    "        else:\n",
    "            new_Au_pos = new_Au_pos_\n",
    "        pos_Au_best_g_tmp, err_Au_best_g_tmp = PSO(SC_energy_func, new_Au_pos[i], i, Au_bounds, num_particles=15, maxiter=30).pso()\n",
    "        new_Au_pos_ = np.vstack((new_Au_pos[:i], np.vstack((pos_Au_best_g_tmp, new_Au_pos[i+1:]))))\n",
    "        pos_Au_final_tmp.append(pos_Au_best_g_tmp)\n",
    "        err_Au_final_tmp.append(err_Au_best_g_tmp)\n",
    "    pos_Au_final.append(pos_Au_final_tmp)\n",
    "    err_Au_final.append(err_Au_final_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best struction:\n",
      " [[ 3.30806347e+00  6.44267281e-01 -1.03140073e+00]\n",
      " [-4.96130384e-01  4.13737753e-02 -5.45863977e-01]\n",
      " [ 5.41751593e-01  3.30380907e+00 -1.12159112e+00]\n",
      " [-1.22170497e+00 -2.72246291e+00 -8.31325269e-02]\n",
      " [-3.32234680e+00  1.21969957e-03 -1.33465928e+00]\n",
      " [ 3.88401430e+00 -9.52961047e-01 -1.15336128e+00]\n",
      " [ 1.19322663e-01 -3.24069072e+00 -1.02342374e+00]\n",
      " [-1.06700428e+00  3.15712666e+00 -5.81425001e-01]\n",
      " [-1.98813622e+00 -8.67697965e-01 -7.53963637e-01]\n",
      " [ 2.50765249e+00 -6.11244662e-01 -2.09227125e-01]\n",
      " [-4.29616745e-01 -1.59804464e+00 -1.13063477e+00]\n",
      " [-2.14067512e-01  1.71885963e+00 -9.26553926e-01]\n",
      " [ 4.19565696e-01  2.37255104e-01  4.28971343e+00]\n",
      " [-4.86536217e-01 -8.00368944e-01  5.28905421e+00]\n",
      " [ 6.54926269e-01  2.59263334e-01  5.97510041e+00]\n",
      " [-7.85044982e-01  8.74986562e-01  5.30882017e+00]\n",
      " [-1.90811488e+00  8.71287346e-01 -1.08974944e+00]\n",
      " [ 4.04633198e+00 -9.97801557e-02  3.09777272e-01]\n",
      " [-8.13958384e-02 -3.77605328e+00  5.29390279e-01]\n",
      " [ 2.28192943e-01  2.71442798e+00  4.28025591e-01]]\n",
      "Lowest energy:\n",
      " -4575.121981622663\n"
     ]
    }
   ],
   "source": [
    "print(\"Best struction for Au20:\\n\", np.array(pos_Au_final)[-1])\r\n",
    "print(\"Lowest energy for Au20:\\n\", np.array(err_Au_final)[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_structure_Au = np.array(pos_Au_final)[-1]\r\n",
    "lowest_energy_Au = np.array(err_Au_final)[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n"
     ]
    }
   ],
   "source": [
    "print(best_structure_Au.shape)"
   ]
  },
  {
   "source": [
    "写入文件"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'e:/Python_code/MathorCup/data/Au_20_best.xyz'\r\n",
    "with open(filename, 'w') as f:\r\n",
    "    f.write(str(best_structure_Au.shape[0]) + \"\\n\")\r\n",
    "    f.write(str(lowest_energy_Au) + \"\\n\")\r\n",
    "    for i in best_structure_Au:\r\n",
    "        f.write(\"Au      \" + str(i[0]) + \"       \" +  str(i[1]) + \"       \" +  str(i[2])  + \"\\n\")\r\n",
    "    \r\n",
    "    # file_object.write(\"Add two words\\n\")\r\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(filename):\r\n",
    "    xyz = []\r\n",
    "    with open(filename, 'r') as f:\r\n",
    "        content = f.read()\r\n",
    "        # print(\"1\", content)\r\n",
    "        contact = content.strip().split('\\n')\r\n",
    "        n = len(contact)\r\n",
    "        # print(\"store\", contact[:2])\r\n",
    "        store = contact[:2]\r\n",
    "        # print()\r\n",
    "        # print(len(contact))\r\n",
    "        # print(\"2\", contact)\r\n",
    "\r\n",
    "        for line in contact:\r\n",
    "            if len(line.split(\"      \")) >= 4:\r\n",
    "                # print(\"3\", line.split(\"      \"))\r\n",
    "                line = line.split('      ')\r\n",
    "                coord = [float(line[1]), float(line[2]), float(line[3])]\r\n",
    "                # print(coord)\r\n",
    "                xyz.append(coord)\r\n",
    "        f.close()\r\n",
    "    xyz = np.array(xyz)\r\n",
    "    scale = np.max(np.abs(np.array(xyz)))\r\n",
    "    xyz /= scale\r\n",
    "    atom = []\r\n",
    "    for i in xyz:\r\n",
    "        new = \"Au      \" + str(i[0]) + \"      \" + str(i[1]) + \"      \" + str(i[2]) + \"\\n\"\r\n",
    "        atom.append(new)\r\n",
    "    # print(atom[0])\r\n",
    "    with open(filename, 'w') as f:\r\n",
    "        f.write(store[0] + \"\\n\")\r\n",
    "        f.write(store[1] + \"\\n\")\r\n",
    "        for i in range(2,n):\r\n",
    "            f.write(atom[i-2])\r\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization(\"./data/Au_20_best.xyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of Au32 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 32*3\r\n",
    "initial_Au32_struct = np.random.uniform(-10,10,num).reshape(32,3)\r\n",
    "Au32_bounds = [(-10, 10), (-10, 10), (-10, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\r\n",
    "pos_Au32_final = []\r\n",
    "err_Au32_final = []\r\n",
    "for epoch in range(epochs):\r\n",
    "    pos_Au32_final_tmp = []\r\n",
    "    err_Au32_final_tmp = []\r\n",
    "    for i in range(initial_Au32_struct.shape[0]):\r\n",
    "        if epoch == 0 and i == 0:\r\n",
    "            new_Au_pos = initial_Au32_struct\r\n",
    "        else:\r\n",
    "            new_Au_pos = new_Au32_pos_\r\n",
    "        pos_Au32_best_g_tmp, err_Au32_best_g_tmp = PSO(SC_energy_func, new_Au_pos[i], i, Au32_bounds, num_particles=20, maxiter=80).pso()\r\n",
    "        new_Au32_pos_ = np.vstack((new_Au_pos[:i], np.vstack((pos_Au32_best_g_tmp, new_Au_pos[i+1:]))))\r\n",
    "        pos_Au32_final_tmp.append(pos_Au32_best_g_tmp)\r\n",
    "        err_Au32_final_tmp.append(err_Au32_best_g_tmp)\r\n",
    "    pos_Au32_final.append(pos_Au32_final_tmp)\r\n",
    "    err_Au32_final.append(err_Au32_final_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10, 20, 50  -6895.116880725851 \\\\\r\n",
    "15, 15, 30  -6960.735413334635 \\\\\r\n",
    "15, 20, 50  -6894.637502089301 \\\\\r\n",
    "10, 20, 80  -7048.019096939294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best Au32 struction:\\n\", np.array(pos_Au32_final)[-1])\n",
    "print(\"Lowest Au32 energy:\\n\", np.array(err_Au32_final)[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_structure_Au32 = np.array(pos_Au32_final)[-1]\r\n",
    "lowest_energy_Au32 = np.array(err_Au32_final)[-1][-1]\r\n",
    "filename = 'e:/Python_code/MathorCup/data/Au32_best.xyz'\r\n",
    "with open(filename, 'w') as f:\r\n",
    "    f.write(str(best_structure_Au32.shape[0]) + \"\\n\")\r\n",
    "    f.write(str(lowest_energy_Au32) + \"\\n\")\r\n",
    "    for i in best_structure_Au32:\r\n",
    "        f.write(\"Au      \" + str(i[0]) + \"       \" +  str(i[1]) + \"       \" +  str(i[2])  + \"\\n\")\r\n",
    "    \r\n",
    "    # file_object.write(\"Add two words\\n\")\r\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization(\"./data/Au32_best.xyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_B45(file_dir):\r\n",
    "    pos = []\r\n",
    "    energy = []\r\n",
    "    file_list = os.listdir(file_dir)\r\n",
    "    for i1 in file_list:\r\n",
    "        orig_os = os.getcwd()\r\n",
    "        pos_tmp = []\r\n",
    "        energy_tmp = []\r\n",
    "        os.chdir(file_dir)    ## ./data/Au20_OPT_1000/\r\n",
    "        with open(i1,'r') as df:\r\n",
    "            dfread = df.read()\r\n",
    "            match_tmp1 = re.findall(r\"Energy:.*\", dfread)\r\n",
    "            # print(match_tmp1[0].split(\":\"))\r\n",
    "            energy_tmp.append(float(match_tmp1[0].split(\":\")[1]))\r\n",
    "            match_tmp2 = re.findall(r\"\\n.*B.*\", dfread)\r\n",
    "            # print(match_tmp2)\r\n",
    "            for pop_i in range(len(match_tmp2)):\r\n",
    "                xyz = match_tmp2[pop_i].split(\"       \")\r\n",
    "                # print(xyz)\r\n",
    "                x, y, z = float(xyz[1]), float(xyz[2]), float(xyz[3])\r\n",
    "                pos_tmp.append([x, y, z])\r\n",
    "        os.chdir(orig_os)\r\n",
    "        pos = pos + pos_tmp\r\n",
    "        energy = energy + energy_tmp\r\n",
    "    pos = np.array(pos)\r\n",
    "    energy = np.array(energy)\r\n",
    "    return pos, energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir_B = 'e:/Python_code/MathorCup/data/B45-_OPT_3751'\r\n",
    "pos_tmp_B, energy_B = load_data_B45(file_dir_B)\r\n",
    "pos_B = pos_tmp_B.reshape(-1, 45, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SC_B_potential_energy_func(x, a):    ## 需要训练的势能函数\r\n",
    "    n = 10\r\n",
    "    m = 8\r\n",
    "    c = 34.408\r\n",
    "    # a = 1\r\n",
    "    epsilon = 35\r\n",
    "\r\n",
    "    dis_mat = np.array(dist_matric(x))\r\n",
    "    tmp1 = (dis_mat / a + np.eye(dis_mat.shape[0])) ** (-n) - np.eye(dis_mat.shape[0])\r\n",
    "    tmp2 = (dis_mat / a + np.eye(dis_mat.shape[0])) ** (-m) - np.eye(dis_mat.shape[0])\r\n",
    "    vr = 1 / 2 * (np.sum(tmp1, axis=1))\r\n",
    "    vd = -c * np.sqrt(np.sum(tmp2, axis=1))\r\n",
    "    energy = epsilon * np.sum(vr + vd)\r\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(label,pred):\r\n",
    "    return np.mean(np.abs(label - pred))\r\n",
    "\r\n",
    "def parameter_selection(data, para_grid):\r\n",
    "    error_total = []\r\n",
    "    for para in para_grid:\r\n",
    "        error_l = 0\r\n",
    "        for i in range(data.shape[0]):\r\n",
    "            ene = SC_B_potential_energy_func(data[i],para)\r\n",
    "            err = criterion(energy_B[i],ene)\r\n",
    "            error_l += err\r\n",
    "        error_total.append(error_l)\r\n",
    "    error_total = np.array(error_total)\r\n",
    "    indx = np.argmin(error_total)\r\n",
    "    return para_grid[indx], np.min(error_total/data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for B: 1.6231155778894473\n",
      "Train error: 39813.97235646427\n"
     ]
    }
   ],
   "source": [
    "B_a = np.linspace(1, 3, 200)\r\n",
    "best_B_a, error_B_train = parameter_selection(pos_B[:3000], B_a)\r\n",
    "print(\"Best parameter for B45:\", best_B_a)\r\n",
    "print(\"Train error:\", error_B_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 34794.18483855465\n"
     ]
    }
   ],
   "source": [
    "_, error_B_test = parameter_selection(pos_B[3000:], [best_B_a])\r\n",
    "print(\"Test error:\", error_B_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SC_B_energy_func(x, idx):\r\n",
    "    n = 10\r\n",
    "    m = 8\r\n",
    "    c = 34.408\r\n",
    "    a = best_B_a\r\n",
    "    # epsilon = best_Au_epsilon\r\n",
    "    epsilon = 35\r\n",
    "    x = np.array(x)\r\n",
    "    new_B_pos_ = np.vstack((new_B_pos[:idx], np.vstack((x, new_B_pos[idx+1:]))))\r\n",
    "    new_dis = np.array(dist_matric(new_B_pos_))\r\n",
    "    tmp1 = (new_dis / a + np.eye(new_dis.shape[0])) ** (-n) - np.eye(new_dis.shape[0])\r\n",
    "    tmp2 = (new_dis / a + np.eye(new_dis.shape[0])) ** (-m) - np.eye(new_dis.shape[0])\r\n",
    "    vr = 1 / 2 * (np.sum(tmp1, axis=1))\r\n",
    "    vd = -c * np.sqrt(np.sum(tmp2, axis=1))\r\n",
    "    energy = epsilon * np.sum(vr + vd)\r\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig pos:\n",
      " [[-2.50828e+00 -1.75993e+00 -4.87900e-01]\n",
      " [-2.42680e+00 -3.33574e+00  3.86300e-02]\n",
      " [-1.04626e+00 -4.15733e+00  1.22470e-01]\n",
      " [ 3.52190e-01 -3.38479e+00 -5.14560e-01]\n",
      " [-1.12871e+00 -8.48860e-01 -1.04054e+00]\n",
      " [ 1.78797e+00 -8.30370e-01 -9.13800e-01]\n",
      " [ 1.74938e+00 -4.14389e+00  2.46060e-01]\n",
      " [-3.95566e+00 -9.11200e-01 -2.15620e-01]\n",
      " [ 1.80277e+00 -2.53237e+00 -4.88970e-01]\n",
      " [-3.80894e+00 -2.53783e+00  2.92750e-01]\n",
      " [ 3.43160e-01 -4.74603e+00  3.51360e-01]\n",
      " [ 3.09279e+00 -3.27960e+00  2.66370e-01]\n",
      " [ 3.17357e+00 -1.67952e+00 -2.60190e-01]\n",
      " [ 4.53172e+00 -7.96520e-01  2.39490e-01]\n",
      " [ 3.12080e-01  1.83058e+00 -1.08665e+00]\n",
      " [ 1.72326e+00  2.55165e+00 -4.29270e-01]\n",
      " [ 3.12807e+00  1.73388e+00 -2.19660e-01]\n",
      " [ 4.54706e+00  8.95460e-01  1.43370e-01]\n",
      " [ 4.32534e+00  2.50059e+00  7.70190e-01]\n",
      " [ 3.00756e+00  3.34177e+00  2.78400e-01]\n",
      " [ 1.64059e+00  4.17036e+00  2.58000e-01]\n",
      " [ 2.67960e-01  3.40327e+00 -5.39570e-01]\n",
      " [ 2.18090e-01  4.74820e+00  3.52430e-01]\n",
      " [-2.51497e+00  3.30378e+00  3.64400e-02]\n",
      " [-1.15840e+00  4.14925e+00  1.08120e-01]\n",
      " [-2.56370e+00  1.73018e+00 -5.31120e-01]\n",
      " [-3.86996e+00  2.48442e+00  2.76300e-01]\n",
      " [-3.98428e+00  8.44690e-01 -2.24320e-01]\n",
      " [-1.18670e+00  2.57757e+00 -7.89240e-01]\n",
      " [-1.11847e+00 -2.59017e+00 -7.64940e-01]\n",
      " [ 3.29333e+00  1.63300e-02 -6.09320e-01]\n",
      " [-1.17071e+00  8.50940e-01 -1.06865e+00]\n",
      " [ 4.40787e+00 -2.44401e+00  7.48920e-01]\n",
      " [-5.05997e+00 -1.73997e+00  8.64830e-01]\n",
      " [-5.19534e+00 -4.57100e-02  5.23080e-01]\n",
      " [-5.10455e+00  1.65043e+00  8.45470e-01]\n",
      " [-6.10519e+00  7.05060e-01  1.60541e+00]\n",
      " [-6.08437e+00 -8.15630e-01  1.61265e+00]\n",
      " [ 1.71671e+00  8.43480e-01 -7.84470e-01]\n",
      " [-2.60942e+00 -1.63600e-02 -7.45890e-01]\n",
      " [ 3.70330e-01 -1.82497e+00 -1.11765e+00]\n",
      " [ 5.47488e+00 -1.51810e+00  1.30058e+00]\n",
      " [ 5.61998e+00  3.40700e-02  1.30453e+00]\n",
      " [ 5.37122e+00  1.56988e+00  1.33866e+00]\n",
      " [ 3.42780e-01  3.05000e-03 -1.09220e+00]]\n",
      "orig energy:\n",
      " -104740.31711375201\n",
      "real energy:\n",
      " -113675.8852964\n"
     ]
    }
   ],
   "source": [
    "pos_B_init = pos_B[0]\r\n",
    "new_B_pos = pos_B_init\r\n",
    "energy_B_init = SC_energy_func(pos_B_init[0], 0)\r\n",
    "print(\"orig pos:\\n\", pos_B_init)\r\n",
    "print(\"orig energy:\\n\", energy_B_init)\r\n",
    "print(\"real energy:\\n\", energy_B[0])\r\n",
    "\r\n",
    "x_max_B = np.max(pos_B[:,:,0])\r\n",
    "x_min_B = np.min(pos_B[:,:,0])\r\n",
    "y_max_B = np.max(pos_B[:,:,1])\r\n",
    "y_min_B = np.min(pos_B[:,:,1])\r\n",
    "z_max_B = np.max(pos_B[:,:,2])\r\n",
    "z_min_B = np.min(pos_B[:,:,2])\r\n",
    "x_B_bounds = (x_min_B, x_max_B)\r\n",
    "y_B_bounds = (y_min_B, y_max_B)\r\n",
    "z_B_bounds = (z_min_B, z_max_B)\r\n",
    "pos_B_final = []\r\n",
    "err_B_final = []\r\n",
    "\r\n",
    "B_bounds = [x_B_bounds, y_B_bounds, z_B_bounds]\r\n",
    "epochs = 10\r\n",
    "for epoch in range(epochs):\r\n",
    "    pos_B_final_tmp = []\r\n",
    "    err_B_final_tmp = []\r\n",
    "    for i in range(pos_B_init.shape[0]):\r\n",
    "        if epoch == 0 and i == 0:\r\n",
    "            new_B_pos = pos_B_init\r\n",
    "        else:\r\n",
    "            new_B_pos = new_B_pos_\r\n",
    "        pos_B_best_g_tmp, err_B_best_g_tmp = PSO(SC_B_energy_func, new_B_pos[i], i, B_bounds, num_particles=15, maxiter=30).pso()\r\n",
    "        new_B_pos_ = np.vstack((new_B_pos[:i], np.vstack((pos_B_best_g_tmp, new_B_pos[i+1:]))))\r\n",
    "        pos_B_final_tmp.append(pos_B_best_g_tmp)\r\n",
    "        err_B_final_tmp.append(err_B_best_g_tmp)\r\n",
    "    pos_B_final.append(pos_B_final_tmp)\r\n",
    "    err_B_final.append(err_B_final_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best struction for B45:\n",
      " [[-1.20498344e+00 -2.68771575e+00 -9.98928375e-02]\n",
      " [-3.37009502e+00 -1.55320392e+00  1.89698600e-01]\n",
      " [-3.40799688e-01 -2.56064652e+00 -5.79520280e-01]\n",
      " [ 1.12641605e+00 -2.57262852e+00 -1.21828125e+00]\n",
      " [-1.20059918e-01  1.03075513e+00 -1.05323887e+00]\n",
      " [ 2.66389264e+00 -2.50528113e+00 -1.80492262e-01]\n",
      " [ 2.17463892e+00 -3.39351122e+00 -1.02445281e-01]\n",
      " [-4.27718084e+00 -1.56200776e+00  6.09714834e-01]\n",
      " [ 1.61947838e+00 -2.52543527e+00 -2.97526899e-01]\n",
      " [-3.70988213e+00 -2.37895150e+00  6.09031865e-01]\n",
      " [ 6.02913694e-01 -2.87021467e+00 -3.79574755e-01]\n",
      " [ 3.16365287e+00 -1.66116838e+00  1.10686667e-01]\n",
      " [ 4.19194620e+00 -1.59753660e+00  1.35146660e-01]\n",
      " [ 3.60617009e+00 -7.13216462e-01  2.95038539e-02]\n",
      " [-1.43614511e+00  3.04576073e+00 -4.12186294e-01]\n",
      " [ 2.67820782e+00  2.55129405e+00  3.37958122e-01]\n",
      " [ 4.02631585e+00  1.64929617e+00  2.51207874e-01]\n",
      " [ 4.19369349e+00  1.74348982e+00  1.29419412e+00]\n",
      " [ 3.57260799e+00  2.39801773e+00  8.06442111e-01]\n",
      " [ 2.43348078e+00  3.51629806e+00  5.10919529e-01]\n",
      " [ 1.75476366e+00  2.82072151e+00  6.47755965e-01]\n",
      " [-9.99003365e-01  3.86246762e+00  2.15500425e-02]\n",
      " [-2.65356553e-01  3.67903327e+00  6.68489364e-01]\n",
      " [-4.27235385e+00  1.54610288e+00  3.93954834e-01]\n",
      " [-4.79711591e-01  2.94576758e+00  6.83804657e-04]\n",
      " [-8.39046561e-01  1.00903972e-01  1.25765590e-01]\n",
      " [-4.83076627e+00  6.93701653e-01  4.48575099e-01]\n",
      " [-4.03796386e+00  7.88914270e-01 -1.80630958e-01]\n",
      " [-9.98644526e-01  2.11689867e+00 -3.36909163e-01]\n",
      " [-2.06561320e+00 -2.28759815e+00  3.03854910e-02]\n",
      " [ 3.63665236e+00  9.39236721e-01  9.08722648e-01]\n",
      " [-6.89565649e-01  1.57646965e-01 -8.96860507e-01]\n",
      " [ 4.66262762e+00 -6.72503705e-01 -2.23009643e-02]\n",
      " [-5.28915187e+00 -9.05817913e-01  8.70396133e-01]\n",
      " [-5.36005548e+00 -1.65179988e-01  1.37366715e-01]\n",
      " [-5.38794952e+00  1.16547955e-01  1.16099150e+00]\n",
      " [-6.20542719e+00 -3.98400348e-01  6.98989633e-01]\n",
      " [-5.90834861e+00 -6.38690913e-01  1.65186463e+00]\n",
      " [ 8.70443382e-02  4.44978897e-01 -1.93733919e-01]\n",
      " [-8.11385641e-01  1.06590134e+00 -2.67812166e-01]\n",
      " [ 1.39184444e+00 -3.45890316e+00 -7.69925659e-01]\n",
      " [ 4.19015156e+00 -8.69369648e-01  8.89699351e-01]\n",
      " [ 4.14506852e+00  1.10968045e-01  4.73895776e-01]\n",
      " [ 4.67103676e+00  9.85870519e-01  7.47357677e-01]\n",
      " [ 3.15951244e-01  1.03355879e-01 -1.14655272e+00]]\n",
      "Lowest energy for B45:\n",
      " -362305.44343958894\n"
     ]
    }
   ],
   "source": [
    "print(\"Best struction for B45:\\n\", np.array(pos_B_final)[-1])\r\n",
    "print(\"Lowest energy for B45:\\n\", np.array(err_B_final)[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_structure_B45 = np.array(pos_B_final)[-1]\r\n",
    "lowest_energy_B45 = np.array(err_B_final)[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'e:/Python_code/MathorCup/data/B45_best.xyz'\r\n",
    "with open(filename, 'w') as f:\r\n",
    "    f.write(str(best_structure_B45.shape[0]) + \"\\n\")\r\n",
    "    f.write(str(lowest_energy_B45) + \"\\n\")\r\n",
    "    for i in best_structure_B45:\r\n",
    "        f.write(\"B       \" + str(i[0]) + \"       \" +  str(i[1]) + \"       \" +  str(i[2])  + \"\\n\")\r\n",
    "    \r\n",
    "    # file_object.write(\"Add two words\\n\")\r\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_B(filename):\r\n",
    "    xyz = []\r\n",
    "    with open(filename, 'r') as f:\r\n",
    "        content = f.read()\r\n",
    "        # print(\"1\", content)\r\n",
    "        contact = content.strip().split('\\n')\r\n",
    "        n = len(contact)\r\n",
    "        # print(\"store\", contact[:2])\r\n",
    "        store = contact[:2]\r\n",
    "        # print()\r\n",
    "        # print(len(contact))\r\n",
    "        # print(\"2\", contact)\r\n",
    "\r\n",
    "        for line in contact:\r\n",
    "            if len(line.split(\"       \")) >= 4:\r\n",
    "                # print(\"3\", line.split(\"      \"))\r\n",
    "                line = line.split('       ')\r\n",
    "                coord = [float(line[1]), float(line[2]), float(line[3])]\r\n",
    "                # print(coord)\r\n",
    "                xyz.append(coord)\r\n",
    "        f.close()\r\n",
    "    xyz = np.array(xyz)\r\n",
    "    scale = np.max(np.abs(np.array(xyz)))\r\n",
    "    xyz /= scale\r\n",
    "    atom = []\r\n",
    "    for i in xyz:\r\n",
    "        new = \"B       \" + str(i[0]) + \"       \" + str(i[1]) + \"       \" + str(i[2]) + \"\\n\"\r\n",
    "        atom.append(new)\r\n",
    "    # print(atom[0])\r\n",
    "    with open(filename, 'w') as f:\r\n",
    "        f.write(store[0] + \"\\n\")\r\n",
    "        f.write(store[1] + \"\\n\")\r\n",
    "        for i in range(2,n):\r\n",
    "            f.write(atom[i-2])\r\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_B(\"e:/Python_code/MathorCup/data/B45_best.xyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of B40 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[(-6.90263, 7.07114), (-5.11455, 5.48891), (-2.79003, 3.75261)]"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_B40 = 40*3\r\n",
    "initial_B40_struct = np.random.uniform(-7,7,num_B40).reshape(40,3)\r\n",
    "B40_bounds = [(-7, 7), (-7, 7), (-7, 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\r\n",
    "pos_B40_final = []\r\n",
    "err_B40_final = []\r\n",
    "for epoch in range(epochs):\r\n",
    "    pos_B40_final_tmp = []\r\n",
    "    err_B40_final_tmp = []\r\n",
    "    for i in range(initial_B40_struct.shape[0]):\r\n",
    "        if epoch == 0 and i == 0:\r\n",
    "            new_B_pos = initial_B40_struct\r\n",
    "        else:\r\n",
    "            new_B_pos = new_B40_pos_\r\n",
    "        pos_B40_best_g_tmp, err_B40_best_g_tmp = PSO(SC_B_energy_func, new_B_pos[i], i, B40_bounds, num_particles=20, maxiter=80).pso()\r\n",
    "        new_B40_pos_ = np.vstack((new_B_pos[:i], np.vstack((pos_B40_best_g_tmp, new_B_pos[i+1:]))))\r\n",
    "        pos_B40_final_tmp.append(pos_B40_best_g_tmp)\r\n",
    "        err_B40_final_tmp.append(err_B40_best_g_tmp)\r\n",
    "    pos_B40_final.append(pos_B40_final_tmp)\r\n",
    "    err_B40_final.append(err_B40_final_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best B40 struction:\\n\", np.array(pos_B40_final)[-1])\r\n",
    "print(\"Lowest B40 energy:\\n\", np.array(err_B40_final)[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_structure_B40 = np.array(pos_B40_final)[-1]\r\n",
    "lowest_energy_B40 = np.array(err_B40_final)[-1][-1]\r\n",
    "filename = 'e:/Python_code/MathorCup/data/B40_best.xyz'\r\n",
    "with open(filename, 'w') as f:\r\n",
    "    f.write(str(best_structure_B40.shape[0]) + \"\\n\")\r\n",
    "    f.write(str(lowest_energy_B40) + \"\\n\")\r\n",
    "    for i in best_structure_B40:\r\n",
    "        f.write(\"B       \" + str(i[0]) + \"       \" +  str(i[1]) + \"       \" +  str(i[2])  + \"\\n\")\r\n",
    "    \r\n",
    "    # file_object.write(\"Add two words\\n\")\r\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization(\"./data/Au32_best.xyz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python374jvsc74a57bd0e288d816212da5324a290161aa1057ff477b98a9261ac15925589a3ec64d30b6",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}